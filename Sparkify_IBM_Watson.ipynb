{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, count, isnull, udf, when\n",
    "\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for a Spark session to start...\n",
      "Spark Initialization Done! ApplicationId = app-20200314214151-0000\n",
      "KERNEL_ID = 9152b68e-3fa6-4c3c-987c-0dcd0d57a93a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(artist='Martin Orford', auth='Logged In', firstName='Joseph', gender='M', itemInSession=20, lastName='Morales', length=597.55057, level='free', location='Corpus Christi, TX', method='PUT', page='NextSong', registration=1532063507000, sessionId=292, song='Grand Designs', status=200, ts=1538352011000, userAgent='\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36\"', userId='293'),\n",
       " Row(artist=\"John Brown's Body\", auth='Logged In', firstName='Sawyer', gender='M', itemInSession=74, lastName='Larson', length=380.21179, level='free', location='Houston-The Woodlands-Sugar Land, TX', method='PUT', page='NextSong', registration=1538069638000, sessionId=97, song='Bulls', status=200, ts=1538352025000, userAgent='\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"', userId='98'),\n",
       " Row(artist='Afroman', auth='Logged In', firstName='Maverick', gender='M', itemInSession=184, lastName='Santiago', length=202.37016, level='paid', location='Orlando-Kissimmee-Sanford, FL', method='PUT', page='NextSong', registration=1535953455000, sessionId=178, song='Because I Got High', status=200, ts=1538352118000, userAgent='\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"', userId='179'),\n",
       " Row(artist=None, auth='Logged In', firstName='Maverick', gender='M', itemInSession=185, lastName='Santiago', length=None, level='paid', location='Orlando-Kissimmee-Sanford, FL', method='PUT', page='Logout', registration=1535953455000, sessionId=178, song=None, status=307, ts=1538352119000, userAgent='\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"', userId='179'),\n",
       " Row(artist='Lily Allen', auth='Logged In', firstName='Gianna', gender='F', itemInSession=22, lastName='Campos', length=194.53342, level='paid', location='Mobile, AL', method='PUT', page='NextSong', registration=1535931018000, sessionId=245, song='Smile (Radio Edit)', status=200, ts=1538352124000, userAgent='Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0', userId='246')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create spark session\n",
    "import ibmos2spark\n",
    "# @hidden_cell\n",
    "credentials = {\n",
    "    'endpoint': 'https://s3.eu-geo.objectstorage.service.networklayer.com',\n",
    "    'service_id': 'iam-ServiceId-1502a5c9-08b3-41f8-8c23-3f1705d3e879',\n",
    "    'iam_service_endpoint': 'https://iam.eu-gb.bluemix.net/oidc/token',\n",
    "    'api_key': 'GxPOyfly2xFRbHdmJ-Ekd-oqsGzrsV_wo_uO2f9th8Nx'\n",
    "}\n",
    "\n",
    "configuration_name = 'os_5af7ef365f01481399b986af65e70d88_configs'\n",
    "cos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "# Since JSON data can be semi-structured and contain additional metadata, it is possible that you might face issues with the DataFrame layout.\n",
    "# Please read the documentation of 'SparkSession.read()' to learn more about the possibilities to adjust the data loading.\n",
    "# PySpark documentation: http://spark.apache.org/docs/2.0.2/api/python/pyspark.sql.html#pyspark.sql.DataFrameReader.json\n",
    "\n",
    "df_data_1 = spark.read.json(cos.url('medium-sparkify-event-data.json', 'sparkify-donotdelete-pr-aovkpzlqasvjfe'))\n",
    "df_data_1.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up: remove all rows where the userId is empty as these are from events where a user was \n",
    "# not logged in which is non-relevant for our churn analysis\n",
    "\n",
    "df_clean = df_data_1.filter(df_data_1.userId != \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|            userId|         sessionId|\n",
      "+-------+------------------+------------------+\n",
      "|  count|            528005|            528005|\n",
      "|   mean| 60268.42669103512|2042.9801820058522|\n",
      "| stddev|109898.82324176628|1433.9981489410682|\n",
      "|    min|                10|                 1|\n",
      "|    max|                99|              4808|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.describe(\"userId\", \"sessionId\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528005"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the hour of day when the song was played to the data frame as a feature\n",
    "get_hour = udf(lambda x: datetime.datetime.fromtimestamp(x / 1000.0). hour)\n",
    "df_clean = df_clean.withColumn(\"hour\", get_hour(df_clean.ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data frame to only contain churn events\n",
    "df_churn = df_clean.where(df_clean.auth==\"Cancelled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a churn column in the dataframe that is 1 for all the events that are from users that have churned\n",
    "list_churnusers = [(row['userId']) for row in df_churn.collect()]\n",
    "\n",
    "df_clean_churn = df_clean.withColumn(\"churn\", when(col(\"userId\").isin(list_churnusers),1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|userId|gender|\n",
      "+------+------+\n",
      "|   188|     0|\n",
      "|   234|     1|\n",
      "|    44|     0|\n",
      "|   273|     1|\n",
      "|    46|     0|\n",
      "|   220|     0|\n",
      "|    41|     0|\n",
      "|   186|     1|\n",
      "|   254|     1|\n",
      "|   280|     1|\n",
      "|100035|     0|\n",
      "|   294|     0|\n",
      "|    72|     0|\n",
      "|300023|     0|\n",
      "|    39|     0|\n",
      "|   287|     1|\n",
      "|100010|     0|\n",
      "|200026|     1|\n",
      "|   210|     0|\n",
      "|   207|     1|\n",
      "+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now its time create the features for each userId\n",
    "# Feature 1: Gender\n",
    "f1 = df_clean_churn.select('userId', 'gender').dropDuplicates().replace(['F', 'M'], ['0', '1'], 'gender').select('userId', col('gender').cast('int'))\n",
    "\n",
    "f1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|level|\n",
      "+------+-----+\n",
      "|100021|    0|\n",
      "|100029|    0|\n",
      "|    94|    1|\n",
      "|200050|    1|\n",
      "|    18|    0|\n",
      "|   185|    0|\n",
      "|200021|    0|\n",
      "|   241|    1|\n",
      "|200001|    0|\n",
      "|   207|    0|\n",
      "|     6|    0|\n",
      "|   190|    1|\n",
      "|   227|    0|\n",
      "|   289|    1|\n",
      "|300022|    1|\n",
      "|   168|    1|\n",
      "|   112|    0|\n",
      "|100035|    1|\n",
      "|   132|    0|\n",
      "|   165|    0|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature 2: Level\n",
    "f2 = df_clean_churn.select('userId', 'level').dropDuplicates().replace(['free', 'paid'], ['0', '1'], 'level').select('userId', col('level').cast('int'))\n",
    "\n",
    "f2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|userId| songs_per_session|\n",
      "+------+------------------+\n",
      "|200002|              62.0|\n",
      "|100010|              48.0|\n",
      "|   296|              22.4|\n",
      "|   125|20.666666666666668|\n",
      "|   124|           114.125|\n",
      "|     7|              30.8|\n",
      "|    51|              53.2|\n",
      "|200037|17.428571428571427|\n",
      "|   205|             209.6|\n",
      "|   169|              14.0|\n",
      "|   272|              48.5|\n",
      "|    15|101.94444444444444|\n",
      "|   234| 72.78260869565217|\n",
      "|   232| 81.56521739130434|\n",
      "|   282| 93.89285714285714|\n",
      "|    54|            64.625|\n",
      "|   155|              35.0|\n",
      "|200043|             51.25|\n",
      "|   154|             23.25|\n",
      "|   132|              56.5|\n",
      "+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature 3: Number of songs listened per session\n",
    "f3  = df_clean_churn.where(df_clean_churn.page == \"NextSong\").groupby(['userId', 'sessionId']).count().groupby('userId').agg({'count' : 'avg'}).withColumnRenamed('avg(count)', 'songs_per_session')\n",
    "\n",
    "f3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|userId|total_songs|\n",
      "+------+-----------+\n",
      "|100010|        137|\n",
      "|200002|        395|\n",
      "|   296|        152|\n",
      "|   125|         84|\n",
      "|   124|       2156|\n",
      "|     7|        600|\n",
      "|    51|        328|\n",
      "|200037|        155|\n",
      "|   205|       1244|\n",
      "|   169|        149|\n",
      "|   272|        131|\n",
      "|   282|       3191|\n",
      "|   232|       2325|\n",
      "|    15|       2173|\n",
      "|    54|        624|\n",
      "|   234|       2021|\n",
      "|200043|        808|\n",
      "|   155|        172|\n",
      "|   154|        126|\n",
      "|   132|        144|\n",
      "+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature 4 : Number of songs played / total number of events per user\n",
    "f4 = df_clean_churn.select('userId', 'song').groupBy('userId').count().withColumnRenamed('count', 'total_songs')\n",
    "f4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|userId|playlist_adds|\n",
      "+------+-------------+\n",
      "|100010|            1|\n",
      "|200002|            6|\n",
      "|   296|            3|\n",
      "|   125|            2|\n",
      "|    51|            8|\n",
      "|   124|           45|\n",
      "|     7|            6|\n",
      "|200037|            4|\n",
      "|   205|           25|\n",
      "|   272|            3|\n",
      "|   282|           66|\n",
      "|   232|           61|\n",
      "|   234|           51|\n",
      "|    54|           15|\n",
      "|    15|           57|\n",
      "|   155|            4|\n",
      "|200043|           23|\n",
      "|100014|           11|\n",
      "|   154|            4|\n",
      "|   132|            4|\n",
      "+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature 5: Number of songs added to playlists\n",
    "f5 = df_clean_churn.select('userId', 'page').where(df_clean_churn.page == 'Add to Playlist').groupBy('userId').count().withColumnRenamed('count', 'playlist_adds')\n",
    "f5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|userId|friends_added|\n",
      "+------+-------------+\n",
      "|   296|            2|\n",
      "|100010|            3|\n",
      "|200002|            2|\n",
      "|   125|            3|\n",
      "|   124|           26|\n",
      "|     7|           16|\n",
      "|    51|            3|\n",
      "|200037|            2|\n",
      "|   205|           21|\n",
      "|   169|            6|\n",
      "|   282|           79|\n",
      "|   232|           43|\n",
      "|    15|           32|\n",
      "|    54|           20|\n",
      "|   234|           17|\n",
      "|200043|           12|\n",
      "|   154|            4|\n",
      "|   132|            4|\n",
      "|100014|            3|\n",
      "|300027|            4|\n",
      "+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature 6: Number of friends added\n",
    "f6 = df_clean_churn.select('userId', 'page').where(df_clean_churn.page == 'Add Friend').groupBy('userId').count().withColumnRenamed('count', 'friends_added')\n",
    "f6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|userId|errors|\n",
      "+------+------+\n",
      "|    51|     2|\n",
      "|   205|     1|\n",
      "|   282|     4|\n",
      "|   232|     1|\n",
      "|    15|     1|\n",
      "|   234|     2|\n",
      "|   155|     1|\n",
      "|   101|     6|\n",
      "|   279|     3|\n",
      "|300017|     4|\n",
      "|   138|     1|\n",
      "|    29|     5|\n",
      "|    69|     1|\n",
      "|    42|     4|\n",
      "|300033|     1|\n",
      "|    87|     5|\n",
      "|    73|     1|\n",
      "|300035|     5|\n",
      "|    30|     7|\n",
      "|   113|     2|\n",
      "+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature 7: Number of errors\n",
    "f7 = df_clean_churn.select('userId', 'page').where(df_clean_churn.page == 'Error').groupBy('userId').count().withColumnRenamed('count', 'errors')\n",
    "f7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|userId|adverts|\n",
      "+------+-------+\n",
      "|   296|      9|\n",
      "|100010|     22|\n",
      "|200002|     11|\n",
      "|   125|      6|\n",
      "|     7|     35|\n",
      "|    51|      1|\n",
      "|   124|      1|\n",
      "|200037|      9|\n",
      "|   169|     13|\n",
      "|   272|     12|\n",
      "|   282|     37|\n",
      "|   232|     38|\n",
      "|   234|     30|\n",
      "|200043|     41|\n",
      "|   154|      9|\n",
      "|   132|      5|\n",
      "|100014|      3|\n",
      "|300027|     26|\n",
      "|   101|      6|\n",
      "|    11|     10|\n",
      "+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature 8: Number of adverts\n",
    "f8 = df_clean_churn.select('userId', 'page').where(df_clean_churn.page == 'Roll Advert').groupBy('userId').count().withColumnRenamed('count', 'adverts')\n",
    "f8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|userId|thumbs_up|\n",
      "+------+---------+\n",
      "|100010|        4|\n",
      "|200002|       15|\n",
      "|   296|        8|\n",
      "|   125|        3|\n",
      "|   124|      102|\n",
      "|    51|       16|\n",
      "|     7|       12|\n",
      "|200037|        5|\n",
      "|   205|       50|\n",
      "|   169|        6|\n",
      "|   272|        7|\n",
      "|   282|      133|\n",
      "|   232|       97|\n",
      "|    15|       93|\n",
      "|    54|       26|\n",
      "|   234|       91|\n",
      "|   155|        7|\n",
      "|200043|       33|\n",
      "|100014|       14|\n",
      "|   154|        4|\n",
      "+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature 9: Number of thumbs up\n",
    "f9 = df_clean_churn.select('userId', 'page').where(df_clean_churn.page == 'Thumbs Up').groupBy('userId').count().withColumnRenamed('count', 'thumbs_up')\n",
    "f9.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|userId|thumbs_down|\n",
      "+------+-----------+\n",
      "|100010|          3|\n",
      "|200002|          5|\n",
      "|   125|          1|\n",
      "|   124|         15|\n",
      "|    51|          1|\n",
      "|     7|          4|\n",
      "|200037|          3|\n",
      "|   205|         10|\n",
      "|   272|          4|\n",
      "|   282|         29|\n",
      "|   232|         17|\n",
      "|    15|         16|\n",
      "|    54|          7|\n",
      "|   234|         22|\n",
      "|200043|         22|\n",
      "|   154|          2|\n",
      "|   132|          1|\n",
      "|100014|          3|\n",
      "|300027|          5|\n",
      "|   200|          2|\n",
      "+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature 10: Number of thumbs down\n",
    "f10 = df_clean_churn.select('userId', 'page').where(df_clean_churn.page == 'Thumbs Down').groupBy('userId').count().withColumnRenamed('count', 'thumbs_down')\n",
    "f10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|churn|\n",
      "+------+-----+\n",
      "|    19|    0|\n",
      "|    73|    0|\n",
      "|   209|    0|\n",
      "|100005|    1|\n",
      "|100030|    1|\n",
      "|100034|    0|\n",
      "|200007|    0|\n",
      "|   184|    0|\n",
      "|    50|    0|\n",
      "|100048|    1|\n",
      "|    30|    0|\n",
      "|100011|    1|\n",
      "|100012|    1|\n",
      "|300051|    0|\n",
      "|   172|    1|\n",
      "|     8|    0|\n",
      "|   192|    0|\n",
      "|   211|    0|\n",
      "|     4|    0|\n",
      "|200018|    0|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "churn = df_clean_churn.select('userId', col('churn').alias('churn')).dropDuplicates()\n",
    "churn.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------------------+-----------+-------------+-------------+------+-------+---------+-----------+-----+\n",
      "|gender|level| songs_per_session|total_songs|playlist_adds|friends_added|errors|adverts|thumbs_up|thumbs_down|churn|\n",
      "+------+-----+------------------+-----------+-------------+-------------+------+-------+---------+-----------+-----+\n",
      "|     1|    1|              53.2|        328|            8|            3|     2|      1|       16|          1|    1|\n",
      "|     0|    0| 81.56521739130434|       2325|           61|           43|     1|     38|       97|         17|    0|\n",
      "|     0|    1| 81.56521739130434|       2325|           61|           43|     1|     38|       97|         17|    0|\n",
      "|     1|    1| 72.78260869565217|       2021|           51|           17|     2|     30|       91|         22|    1|\n",
      "|     1|    0| 72.78260869565217|       2021|           51|           17|     2|     30|       91|         22|    1|\n",
      "|     1|    0| 93.89285714285714|       3191|           66|           79|     4|     37|      133|         29|    0|\n",
      "|     1|    1| 93.89285714285714|       3191|           66|           79|     4|     37|      133|         29|    0|\n",
      "|     1|    0|108.39622641509433|       6842|          165|          117|     6|      6|      305|         55|    0|\n",
      "|     1|    1|108.39622641509433|       6842|          165|          117|     6|      6|      305|         55|    0|\n",
      "|     0|    0|55.111111111111114|        620|           14|            8|     3|     11|       22|          3|    0|\n",
      "|     0|    1|55.111111111111114|        620|           14|            8|     3|     11|       22|          3|    0|\n",
      "|     1|    0| 33.38461538461539|        576|           10|            7|     1|     37|       27|          4|    0|\n",
      "|     0|    1| 61.18571428571428|       5266|          125|           98|     4|      5|      388|         25|    0|\n",
      "|     1|    1|  48.8974358974359|       2350|           48|           40|     5|     73|       90|         17|    0|\n",
      "|     1|    0|  48.8974358974359|       2350|           48|           40|     5|     73|       90|         17|    0|\n",
      "|     0|    0| 49.81818181818182|        684|           17|           13|     1|     28|       25|          4|    0|\n",
      "|     0|    1| 49.81818181818182|        684|           17|           13|     1|     28|       25|          4|    0|\n",
      "|     0|    0| 79.80392156862744|       4952|          111|           71|     4|    101|      187|         41|    0|\n",
      "|     0|    1| 79.80392156862744|       4952|          111|           71|     4|    101|      187|         41|    0|\n",
      "|     0|    0|              20.0|        307|            5|            4|     1|     20|        9|          1|    0|\n",
      "+------+-----+------------------+-----------+-------------+-------------+------+-------+---------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# as a final step we combine all the features with the churn column into a feature_data dataframe\n",
    "\n",
    "feature_data = f1.join(f2, 'userId', 'inner').join(f3, 'userId', 'inner').join(f4, 'userId', 'inner')\\\n",
    "             .join(f5, 'userId', 'inner').join(f6, 'userId', 'inner').join(f7, 'userId', 'inner')\\\n",
    "             .join(f8, 'userId', 'inner').join(f9, 'userId', 'inner').join(f10, 'userId', 'inner').join(churn, 'userId', 'inner').drop('userId')\n",
    "\n",
    "feature_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------------------+-----------+-------------+-------------+------+-------+---------+-----------+-----+--------------------+\n",
      "|gender|level| songs_per_session|total_songs|playlist_adds|friends_added|errors|adverts|thumbs_up|thumbs_down|churn| vectorized_features|\n",
      "+------+-----+------------------+-----------+-------------+-------------+------+-------+---------+-----------+-----+--------------------+\n",
      "|     1|    1|              53.2|        328|            8|            3|     2|      1|       16|          1|    1|[1.0,1.0,53.2,328...|\n",
      "|     0|    0| 81.56521739130434|       2325|           61|           43|     1|     38|       97|         17|    0|[0.0,0.0,81.56521...|\n",
      "|     0|    1| 81.56521739130434|       2325|           61|           43|     1|     38|       97|         17|    0|[0.0,1.0,81.56521...|\n",
      "|     1|    1| 72.78260869565217|       2021|           51|           17|     2|     30|       91|         22|    1|[1.0,1.0,72.78260...|\n",
      "|     1|    0| 72.78260869565217|       2021|           51|           17|     2|     30|       91|         22|    1|[1.0,0.0,72.78260...|\n",
      "|     1|    1| 93.89285714285714|       3191|           66|           79|     4|     37|      133|         29|    0|[1.0,1.0,93.89285...|\n",
      "|     1|    0| 93.89285714285714|       3191|           66|           79|     4|     37|      133|         29|    0|[1.0,0.0,93.89285...|\n",
      "|     1|    0|108.39622641509433|       6842|          165|          117|     6|      6|      305|         55|    0|[1.0,0.0,108.3962...|\n",
      "|     1|    1|108.39622641509433|       6842|          165|          117|     6|      6|      305|         55|    0|[1.0,1.0,108.3962...|\n",
      "|     0|    0|55.111111111111114|        620|           14|            8|     3|     11|       22|          3|    0|[0.0,0.0,55.11111...|\n",
      "|     0|    1|55.111111111111114|        620|           14|            8|     3|     11|       22|          3|    0|[0.0,1.0,55.11111...|\n",
      "|     1|    0| 33.38461538461539|        576|           10|            7|     1|     37|       27|          4|    0|[1.0,0.0,33.38461...|\n",
      "|     0|    1| 61.18571428571428|       5266|          125|           98|     4|      5|      388|         25|    0|[0.0,1.0,61.18571...|\n",
      "|     1|    1|  48.8974358974359|       2350|           48|           40|     5|     73|       90|         17|    0|[1.0,1.0,48.89743...|\n",
      "|     1|    0|  48.8974358974359|       2350|           48|           40|     5|     73|       90|         17|    0|[1.0,0.0,48.89743...|\n",
      "|     0|    0| 49.81818181818182|        684|           17|           13|     1|     28|       25|          4|    0|[0.0,0.0,49.81818...|\n",
      "|     0|    1| 49.81818181818182|        684|           17|           13|     1|     28|       25|          4|    0|[0.0,1.0,49.81818...|\n",
      "|     0|    0| 79.80392156862744|       4952|          111|           71|     4|    101|      187|         41|    0|[0.0,0.0,79.80392...|\n",
      "|     0|    1| 79.80392156862744|       4952|          111|           71|     4|    101|      187|         41|    0|[0.0,1.0,79.80392...|\n",
      "|     0|    0|              20.0|        307|            5|            4|     1|     20|        9|          1|    0|[0.0,0.0,20.0,307...|\n",
      "+------+-----+------------------+-----------+-------------+-------------+------+-------+---------+-----------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# before we start the modelling we need to combine the features into a features vector\n",
    "feature_columns = ['gender', 'level', 'songs_per_session', 'total_songs', 'playlist_adds', 'friends_added', 'errors', 'adverts', 'thumbs_up', 'thumbs_down']\n",
    "assmbler = VectorAssembler(inputCols = feature_columns, outputCol = \"vectorized_features\")\n",
    "feature_data = assmbler.transform(feature_data)\n",
    "feature_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to enable our machine learning models to work with our data without getting bias though different scales\n",
    "# we need to scale the data\n",
    "scaler = StandardScaler(inputCol = 'vectorized_features', outputCol = \"scaled_features\", withStd = True, withMean = False)\n",
    "scaler_model = scaler.fit(feature_data)\n",
    "feature_data = scaler_model.transform(feature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we prepare the data into label and features vector as well was renaming these to use the standard \n",
    "# column names used by the used classifiers.\n",
    "feature_data_final = feature_data.select(['churn', 'scaled_features'])\n",
    "feature_data_final = feature_data_final.selectExpr(\"churn as label\", \"scaled_features as features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data in training and testing data sets.\n",
    "train_data , test_data = feature_data_final.randomSplit([0.7,0.3], seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7845075906022849]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting a Random Forest Classifier\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "mce_f1 = MulticlassClassificationEvaluator(metricName = 'f1')\n",
    "parameter_grid = ParamGridBuilder().build()\n",
    "\n",
    "cv_rf = CrossValidator(estimator = rfc, estimatorParamMaps = parameter_grid, evaluator = mce_f1, numFolds = 2)\n",
    "\n",
    "cv_rf_model = cv_rf.fit(train_data)\n",
    "cv_rf_model.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.8198198198198198\n",
      "accuracy: 0.7691441441441441\n",
      "area under ROC: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the results with regard to f1 score and accuracy\n",
    "test_result_rf = cv_rf_model.transform(test_data)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol = \"prediction\")\n",
    "evaluator_ROC = BinaryClassificationEvaluator(rawPredictionCol='prediction', metricName='areaUnderROC')\n",
    "print(\"f1 score: \" + str(evaluator.evaluate(test_result_rf, {evaluator.metricName : \"accuracy\"})))\n",
    "print(\"accuracy: \" + str(evaluator.evaluate(test_result_rf, {evaluator.metricName : \"f1\"})))\n",
    "print(\"area under ROC: \" + str(evaluator_ROC.evaluate(test_result_rf, {evaluator.metricName : \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7306828246070239]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting a Gradient Boost Tree Classifier\n",
    "gbtc = GBTClassifier(maxIter = 5, maxDepth = 5, seed = 42)\n",
    "\n",
    "cv_gbtc = CrossValidator(estimator = gbtc, estimatorParamMaps = parameter_grid, evaluator = mce_f1, numFolds = 2)\n",
    "\n",
    "cv_gbtc_model = cv_gbtc.fit(train_data)\n",
    "cv_gbtc_model.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.8918918918918919\n",
      "accuracy: 0.8902609506057781\n",
      "area under ROC: 0.8309302325581395\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the results with regard to f1 score and accuracy\n",
    "test_result_gbtc = cv_gbtc_model.transform(test_data)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol = \"prediction\")\n",
    "evaluator_ROC = BinaryClassificationEvaluator(rawPredictionCol='prediction', metricName='areaUnderROC')\n",
    "print(\"f1 score: \" + str(evaluator.evaluate(test_result_gbtc, {evaluator.metricName : \"accuracy\"})))\n",
    "print(\"accuracy: \" + str(evaluator.evaluate(test_result_gbtc, {evaluator.metricName : \"f1\"})))\n",
    "print(\"area under ROC: \" + str(evaluator_ROC.evaluate(test_result_gbtc, {evaluator.metricName : \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8224143563442641,\n",
       " 0.7984631218726905,\n",
       " 0.8203306263120651,\n",
       " 0.8029130734028762,\n",
       " 0.8172722614559473,\n",
       " 0.8029130734028762,\n",
       " 0.8137199487746023,\n",
       " 0.8029130734028762]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting a Gradient Boost Tree Classifier and using Grid Search to find the optimal hyperparameters\n",
    "gbtc_final = GBTClassifier(maxIter = 5, maxDepth = 5, seed = 42)\n",
    "parameter_grid_final = ParamGridBuilder().addGrid(gbtc_final.maxIter, [5, 10, 15, 20]).addGrid(gbtc_final.maxDepth, [5, 10]).build()\n",
    "\n",
    "cv_gbtc_final = CrossValidator(estimator = gbtc_final, estimatorParamMaps = parameter_grid_final, evaluator = mce_f1, numFolds = 3)\n",
    "cv_gbtc_model_final = cv_gbtc_final.fit(train_data)\n",
    "cv_gbtc_model_final.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.8918918918918919\n",
      "accuracy: 0.8902609506057781\n",
      "area under ROC: 0.8309302325581395\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the results with regard to f1 score and accuracy\n",
    "test_result_gbtc_final = cv_gbtc_model_final.transform(test_data)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol = \"prediction\")\n",
    "evaluator_ROC = BinaryClassificationEvaluator(rawPredictionCol='prediction', metricName='areaUnderROC')\n",
    "\n",
    "print(\"f1 score: \" + str(evaluator.evaluate(test_result_gbtc_final, {evaluator.metricName : \"accuracy\"})))\n",
    "print(\"accuracy: \" + str(evaluator.evaluate(test_result_gbtc_final, {evaluator.metricName : \"f1\"})))\n",
    "print(\"area under ROC: \" + str(evaluator_ROC.evaluate(test_result_gbtc_final, {evaluator.metricName : \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 with Spark",
   "language": "python3",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
